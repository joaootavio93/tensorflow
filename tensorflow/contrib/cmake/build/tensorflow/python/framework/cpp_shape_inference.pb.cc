// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/python/framework/cpp_shape_inference.proto

#define INTERNAL_SUPPRESS_PROTOBUF_FIELD_DEPRECATION
#include "tensorflow/python/framework/cpp_shape_inference.pb.h"

#include <algorithm>

#include <google/protobuf/stubs/common.h>
#include <google/protobuf/stubs/port.h>
#include <google/protobuf/stubs/once.h>
#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/wire_format_lite_inl.h>
#include <google/protobuf/descriptor.h>
#include <google/protobuf/generated_message_reflection.h>
#include <google/protobuf/reflection_ops.h>
#include <google/protobuf/wire_format.h>
// @@protoc_insertion_point(includes)

namespace tensorflow {

namespace {

const ::google::protobuf::Descriptor* CppShapeInferenceResult_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  CppShapeInferenceResult_reflection_ = NULL;
const ::google::protobuf::Descriptor* CppShapeInferenceResult_HandleShapeAndType_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  CppShapeInferenceResult_HandleShapeAndType_reflection_ = NULL;
const ::google::protobuf::Descriptor* CppShapeInferenceResult_HandleData_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  CppShapeInferenceResult_HandleData_reflection_ = NULL;
const ::google::protobuf::Descriptor* CppShapeInferenceInputsNeeded_descriptor_ = NULL;
const ::google::protobuf::internal::GeneratedMessageReflection*
  CppShapeInferenceInputsNeeded_reflection_ = NULL;

}  // namespace


void protobuf_AssignDesc_tensorflow_2fpython_2fframework_2fcpp_5fshape_5finference_2eproto() GOOGLE_ATTRIBUTE_COLD;
void protobuf_AssignDesc_tensorflow_2fpython_2fframework_2fcpp_5fshape_5finference_2eproto() {
  protobuf_AddDesc_tensorflow_2fpython_2fframework_2fcpp_5fshape_5finference_2eproto();
  const ::google::protobuf::FileDescriptor* file =
    ::google::protobuf::DescriptorPool::generated_pool()->FindFileByName(
      "tensorflow/python/framework/cpp_shape_inference.proto");
  GOOGLE_CHECK(file != NULL);
  CppShapeInferenceResult_descriptor_ = file->message_type(0);
  static const int CppShapeInferenceResult_offsets_[2] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CppShapeInferenceResult, shape_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CppShapeInferenceResult, handle_data_),
  };
  CppShapeInferenceResult_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      CppShapeInferenceResult_descriptor_,
      CppShapeInferenceResult::internal_default_instance(),
      CppShapeInferenceResult_offsets_,
      -1,
      -1,
      -1,
      sizeof(CppShapeInferenceResult),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CppShapeInferenceResult, _internal_metadata_));
  CppShapeInferenceResult_HandleShapeAndType_descriptor_ = CppShapeInferenceResult_descriptor_->nested_type(0);
  static const int CppShapeInferenceResult_HandleShapeAndType_offsets_[2] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CppShapeInferenceResult_HandleShapeAndType, shape_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CppShapeInferenceResult_HandleShapeAndType, dtype_),
  };
  CppShapeInferenceResult_HandleShapeAndType_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      CppShapeInferenceResult_HandleShapeAndType_descriptor_,
      CppShapeInferenceResult_HandleShapeAndType::internal_default_instance(),
      CppShapeInferenceResult_HandleShapeAndType_offsets_,
      -1,
      -1,
      -1,
      sizeof(CppShapeInferenceResult_HandleShapeAndType),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CppShapeInferenceResult_HandleShapeAndType, _internal_metadata_));
  CppShapeInferenceResult_HandleData_descriptor_ = CppShapeInferenceResult_descriptor_->nested_type(1);
  static const int CppShapeInferenceResult_HandleData_offsets_[2] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CppShapeInferenceResult_HandleData, is_set_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CppShapeInferenceResult_HandleData, shape_and_type_),
  };
  CppShapeInferenceResult_HandleData_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      CppShapeInferenceResult_HandleData_descriptor_,
      CppShapeInferenceResult_HandleData::internal_default_instance(),
      CppShapeInferenceResult_HandleData_offsets_,
      -1,
      -1,
      -1,
      sizeof(CppShapeInferenceResult_HandleData),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CppShapeInferenceResult_HandleData, _internal_metadata_));
  CppShapeInferenceInputsNeeded_descriptor_ = file->message_type(1);
  static const int CppShapeInferenceInputsNeeded_offsets_[2] = {
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CppShapeInferenceInputsNeeded, input_tensors_needed_),
    GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CppShapeInferenceInputsNeeded, input_tensors_as_shapes_needed_),
  };
  CppShapeInferenceInputsNeeded_reflection_ =
    ::google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(
      CppShapeInferenceInputsNeeded_descriptor_,
      CppShapeInferenceInputsNeeded::internal_default_instance(),
      CppShapeInferenceInputsNeeded_offsets_,
      -1,
      -1,
      -1,
      sizeof(CppShapeInferenceInputsNeeded),
      GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CppShapeInferenceInputsNeeded, _internal_metadata_));
}

namespace {

GOOGLE_PROTOBUF_DECLARE_ONCE(protobuf_AssignDescriptors_once_);
void protobuf_AssignDescriptorsOnce() {
  ::google::protobuf::GoogleOnceInit(&protobuf_AssignDescriptors_once_,
                 &protobuf_AssignDesc_tensorflow_2fpython_2fframework_2fcpp_5fshape_5finference_2eproto);
}

void protobuf_RegisterTypes(const ::std::string&) GOOGLE_ATTRIBUTE_COLD;
void protobuf_RegisterTypes(const ::std::string&) {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      CppShapeInferenceResult_descriptor_, CppShapeInferenceResult::internal_default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      CppShapeInferenceResult_HandleShapeAndType_descriptor_, CppShapeInferenceResult_HandleShapeAndType::internal_default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      CppShapeInferenceResult_HandleData_descriptor_, CppShapeInferenceResult_HandleData::internal_default_instance());
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedMessage(
      CppShapeInferenceInputsNeeded_descriptor_, CppShapeInferenceInputsNeeded::internal_default_instance());
}

}  // namespace

void protobuf_ShutdownFile_tensorflow_2fpython_2fframework_2fcpp_5fshape_5finference_2eproto() {
  CppShapeInferenceResult_default_instance_.Shutdown();
  delete CppShapeInferenceResult_reflection_;
  CppShapeInferenceResult_HandleShapeAndType_default_instance_.Shutdown();
  delete CppShapeInferenceResult_HandleShapeAndType_reflection_;
  CppShapeInferenceResult_HandleData_default_instance_.Shutdown();
  delete CppShapeInferenceResult_HandleData_reflection_;
  CppShapeInferenceInputsNeeded_default_instance_.Shutdown();
  delete CppShapeInferenceInputsNeeded_reflection_;
}

void protobuf_InitDefaults_tensorflow_2fpython_2fframework_2fcpp_5fshape_5finference_2eproto_impl() {
  GOOGLE_PROTOBUF_VERIFY_VERSION;

  ::tensorflow::protobuf_InitDefaults_tensorflow_2fcore_2fframework_2ftypes_2eproto();
  ::tensorflow::protobuf_InitDefaults_tensorflow_2fcore_2fframework_2ftensor_5fshape_2eproto();
  CppShapeInferenceResult_default_instance_.DefaultConstruct();
  CppShapeInferenceResult_HandleShapeAndType_default_instance_.DefaultConstruct();
  CppShapeInferenceResult_HandleData_default_instance_.DefaultConstruct();
  CppShapeInferenceInputsNeeded_default_instance_.DefaultConstruct();
  CppShapeInferenceResult_default_instance_.get_mutable()->InitAsDefaultInstance();
  CppShapeInferenceResult_HandleShapeAndType_default_instance_.get_mutable()->InitAsDefaultInstance();
  CppShapeInferenceResult_HandleData_default_instance_.get_mutable()->InitAsDefaultInstance();
  CppShapeInferenceInputsNeeded_default_instance_.get_mutable()->InitAsDefaultInstance();
}

GOOGLE_PROTOBUF_DECLARE_ONCE(protobuf_InitDefaults_tensorflow_2fpython_2fframework_2fcpp_5fshape_5finference_2eproto_once_);
void protobuf_InitDefaults_tensorflow_2fpython_2fframework_2fcpp_5fshape_5finference_2eproto() {
  ::google::protobuf::GoogleOnceInit(&protobuf_InitDefaults_tensorflow_2fpython_2fframework_2fcpp_5fshape_5finference_2eproto_once_,
                 &protobuf_InitDefaults_tensorflow_2fpython_2fframework_2fcpp_5fshape_5finference_2eproto_impl);
}
void protobuf_AddDesc_tensorflow_2fpython_2fframework_2fcpp_5fshape_5finference_2eproto_impl() {
  GOOGLE_PROTOBUF_VERIFY_VERSION;

  protobuf_InitDefaults_tensorflow_2fpython_2fframework_2fcpp_5fshape_5finference_2eproto();
  ::google::protobuf::DescriptorPool::InternalAddGeneratedFile(
    "\n5tensorflow/python/framework/cpp_shape_"
    "inference.proto\022\ntensorflow\032%tensorflow/"
    "core/framework/types.proto\032,tensorflow/c"
    "ore/framework/tensor_shape.proto\"\355\002\n\027Cpp"
    "ShapeInferenceResult\022+\n\005shape\030\001 \001(\0132\034.te"
    "nsorflow.TensorShapeProto\022C\n\013handle_data"
    "\030\004 \001(\0132..tensorflow.CppShapeInferenceRes"
    "ult.HandleData\032f\n\022HandleShapeAndType\022+\n\005"
    "shape\030\001 \001(\0132\034.tensorflow.TensorShapeProt"
    "o\022#\n\005dtype\030\002 \001(\0162\024.tensorflow.DataType\032l"
    "\n\nHandleData\022\016\n\006is_set\030\001 \001(\010\022N\n\016shape_an"
    "d_type\030\002 \003(\01326.tensorflow.CppShapeInfere"
    "nceResult.HandleShapeAndTypeJ\004\010\002\020\003J\004\010\003\020\004"
    "\"e\n\035CppShapeInferenceInputsNeeded\022\034\n\024inp"
    "ut_tensors_needed\030\001 \003(\005\022&\n\036input_tensors"
    "_as_shapes_needed\030\002 \003(\005B\003\370\001\001b\006proto3", 636);
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedFile(
    "tensorflow/python/framework/cpp_shape_inference.proto", &protobuf_RegisterTypes);
  ::tensorflow::protobuf_AddDesc_tensorflow_2fcore_2fframework_2ftypes_2eproto();
  ::tensorflow::protobuf_AddDesc_tensorflow_2fcore_2fframework_2ftensor_5fshape_2eproto();
  ::google::protobuf::internal::OnShutdown(&protobuf_ShutdownFile_tensorflow_2fpython_2fframework_2fcpp_5fshape_5finference_2eproto);
}

GOOGLE_PROTOBUF_DECLARE_ONCE(protobuf_AddDesc_tensorflow_2fpython_2fframework_2fcpp_5fshape_5finference_2eproto_once_);
void protobuf_AddDesc_tensorflow_2fpython_2fframework_2fcpp_5fshape_5finference_2eproto() {
  ::google::protobuf::GoogleOnceInit(&protobuf_AddDesc_tensorflow_2fpython_2fframework_2fcpp_5fshape_5finference_2eproto_once_,
                 &protobuf_AddDesc_tensorflow_2fpython_2fframework_2fcpp_5fshape_5finference_2eproto_impl);
}
// Force AddDescriptors() to be called at static initialization time.
struct StaticDescriptorInitializer_tensorflow_2fpython_2fframework_2fcpp_5fshape_5finference_2eproto {
  StaticDescriptorInitializer_tensorflow_2fpython_2fframework_2fcpp_5fshape_5finference_2eproto() {
    protobuf_AddDesc_tensorflow_2fpython_2fframework_2fcpp_5fshape_5finference_2eproto();
  }
} static_descriptor_initializer_tensorflow_2fpython_2fframework_2fcpp_5fshape_5finference_2eproto_;

namespace {

static void MergeFromFail(int line) GOOGLE_ATTRIBUTE_COLD GOOGLE_ATTRIBUTE_NORETURN;
static void MergeFromFail(int line) {
  ::google::protobuf::internal::MergeFromFail(__FILE__, line);
}

}  // namespace


// ===================================================================

void CppShapeInferenceResult_HandleShapeAndType::_slow_mutable_shape() {
  shape_ = ::google::protobuf::Arena::CreateMessage< ::tensorflow::TensorShapeProto >(
      GetArenaNoVirtual());
}
::tensorflow::TensorShapeProto* CppShapeInferenceResult_HandleShapeAndType::_slow_release_shape() {
  if (shape_ == NULL) {
    return NULL;
  } else {
    ::tensorflow::TensorShapeProto* temp = new ::tensorflow::TensorShapeProto(*shape_);
    shape_ = NULL;
    return temp;
  }
}
::tensorflow::TensorShapeProto* CppShapeInferenceResult_HandleShapeAndType::unsafe_arena_release_shape() {
  // @@protoc_insertion_point(field_unsafe_arena_release:tensorflow.CppShapeInferenceResult.HandleShapeAndType.shape)
  
  ::tensorflow::TensorShapeProto* temp = shape_;
  shape_ = NULL;
  return temp;
}
void CppShapeInferenceResult_HandleShapeAndType::_slow_set_allocated_shape(
    ::google::protobuf::Arena* message_arena, ::tensorflow::TensorShapeProto** shape) {
    if (message_arena != NULL && 
        ::google::protobuf::Arena::GetArena(*shape) == NULL) {
      message_arena->Own(*shape);
    } else if (message_arena !=
               ::google::protobuf::Arena::GetArena(*shape)) {
      ::tensorflow::TensorShapeProto* new_shape = 
            ::google::protobuf::Arena::CreateMessage< ::tensorflow::TensorShapeProto >(
            message_arena);
      new_shape->CopyFrom(**shape);
      *shape = new_shape;
    }
}
void CppShapeInferenceResult_HandleShapeAndType::unsafe_arena_set_allocated_shape(
    ::tensorflow::TensorShapeProto* shape) {
  if (GetArenaNoVirtual() == NULL) {
    delete shape_;
  }
  shape_ = shape;
  if (shape) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.CppShapeInferenceResult.HandleShapeAndType.shape)
}
#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int CppShapeInferenceResult_HandleShapeAndType::kShapeFieldNumber;
const int CppShapeInferenceResult_HandleShapeAndType::kDtypeFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

CppShapeInferenceResult_HandleShapeAndType::CppShapeInferenceResult_HandleShapeAndType()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  if (this != internal_default_instance()) protobuf_InitDefaults_tensorflow_2fpython_2fframework_2fcpp_5fshape_5finference_2eproto();
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.CppShapeInferenceResult.HandleShapeAndType)
}
CppShapeInferenceResult_HandleShapeAndType::CppShapeInferenceResult_HandleShapeAndType(::google::protobuf::Arena* arena)
  : ::google::protobuf::Message(),
  _internal_metadata_(arena) {
#ifdef GOOGLE_PROTOBUF_NO_STATIC_INITIALIZER
  protobuf_InitDefaults_tensorflow_2fpython_2fframework_2fcpp_5fshape_5finference_2eproto();
#endif  // GOOGLE_PROTOBUF_NO_STATIC_INITIALIZER
  SharedCtor();
  RegisterArenaDtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.CppShapeInferenceResult.HandleShapeAndType)
}

void CppShapeInferenceResult_HandleShapeAndType::InitAsDefaultInstance() {
  shape_ = const_cast< ::tensorflow::TensorShapeProto*>(
      ::tensorflow::TensorShapeProto::internal_default_instance());
}

CppShapeInferenceResult_HandleShapeAndType::CppShapeInferenceResult_HandleShapeAndType(const CppShapeInferenceResult_HandleShapeAndType& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  UnsafeMergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.CppShapeInferenceResult.HandleShapeAndType)
}

void CppShapeInferenceResult_HandleShapeAndType::SharedCtor() {
  shape_ = NULL;
  dtype_ = 0;
  _cached_size_ = 0;
}

CppShapeInferenceResult_HandleShapeAndType::~CppShapeInferenceResult_HandleShapeAndType() {
  // @@protoc_insertion_point(destructor:tensorflow.CppShapeInferenceResult.HandleShapeAndType)
  SharedDtor();
}

void CppShapeInferenceResult_HandleShapeAndType::SharedDtor() {
  ::google::protobuf::Arena* arena = GetArenaNoVirtual();
  if (arena != NULL) {
    return;
  }

  if (this != &CppShapeInferenceResult_HandleShapeAndType_default_instance_.get()) {
    delete shape_;
  }
}

void CppShapeInferenceResult_HandleShapeAndType::ArenaDtor(void* object) {
  CppShapeInferenceResult_HandleShapeAndType* _this = reinterpret_cast< CppShapeInferenceResult_HandleShapeAndType* >(object);
  (void)_this;
}
void CppShapeInferenceResult_HandleShapeAndType::RegisterArenaDtor(::google::protobuf::Arena* arena) {
}
void CppShapeInferenceResult_HandleShapeAndType::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* CppShapeInferenceResult_HandleShapeAndType::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return CppShapeInferenceResult_HandleShapeAndType_descriptor_;
}

const CppShapeInferenceResult_HandleShapeAndType& CppShapeInferenceResult_HandleShapeAndType::default_instance() {
  protobuf_InitDefaults_tensorflow_2fpython_2fframework_2fcpp_5fshape_5finference_2eproto();
  return *internal_default_instance();
}

::google::protobuf::internal::ExplicitlyConstructed<CppShapeInferenceResult_HandleShapeAndType> CppShapeInferenceResult_HandleShapeAndType_default_instance_;

CppShapeInferenceResult_HandleShapeAndType* CppShapeInferenceResult_HandleShapeAndType::New(::google::protobuf::Arena* arena) const {
  return ::google::protobuf::Arena::CreateMessage<CppShapeInferenceResult_HandleShapeAndType>(arena);
}

void CppShapeInferenceResult_HandleShapeAndType::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.CppShapeInferenceResult.HandleShapeAndType)
  if (GetArenaNoVirtual() == NULL && shape_ != NULL) delete shape_;
  shape_ = NULL;
  dtype_ = 0;
}

bool CppShapeInferenceResult_HandleShapeAndType::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.CppShapeInferenceResult.HandleShapeAndType)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional .tensorflow.TensorShapeProto shape = 1;
      case 1: {
        if (tag == 10) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_shape()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(16)) goto parse_dtype;
        break;
      }

      // optional .tensorflow.DataType dtype = 2;
      case 2: {
        if (tag == 16) {
         parse_dtype:
          int value;
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   int, ::google::protobuf::internal::WireFormatLite::TYPE_ENUM>(
                 input, &value)));
          set_dtype(static_cast< ::tensorflow::DataType >(value));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.CppShapeInferenceResult.HandleShapeAndType)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.CppShapeInferenceResult.HandleShapeAndType)
  return false;
#undef DO_
}

void CppShapeInferenceResult_HandleShapeAndType::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.CppShapeInferenceResult.HandleShapeAndType)
  // optional .tensorflow.TensorShapeProto shape = 1;
  if (this->has_shape()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, *this->shape_, output);
  }

  // optional .tensorflow.DataType dtype = 2;
  if (this->dtype() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteEnum(
      2, this->dtype(), output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.CppShapeInferenceResult.HandleShapeAndType)
}

::google::protobuf::uint8* CppShapeInferenceResult_HandleShapeAndType::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  (void)deterministic; // Unused
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.CppShapeInferenceResult.HandleShapeAndType)
  // optional .tensorflow.TensorShapeProto shape = 1;
  if (this->has_shape()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        1, *this->shape_, false, target);
  }

  // optional .tensorflow.DataType dtype = 2;
  if (this->dtype() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteEnumToArray(
      2, this->dtype(), target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.CppShapeInferenceResult.HandleShapeAndType)
  return target;
}

size_t CppShapeInferenceResult_HandleShapeAndType::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.CppShapeInferenceResult.HandleShapeAndType)
  size_t total_size = 0;

  // optional .tensorflow.TensorShapeProto shape = 1;
  if (this->has_shape()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->shape_);
  }

  // optional .tensorflow.DataType dtype = 2;
  if (this->dtype() != 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::EnumSize(this->dtype());
  }

  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = cached_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void CppShapeInferenceResult_HandleShapeAndType::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.CppShapeInferenceResult.HandleShapeAndType)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  const CppShapeInferenceResult_HandleShapeAndType* source =
      ::google::protobuf::internal::DynamicCastToGenerated<const CppShapeInferenceResult_HandleShapeAndType>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.CppShapeInferenceResult.HandleShapeAndType)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.CppShapeInferenceResult.HandleShapeAndType)
    UnsafeMergeFrom(*source);
  }
}

void CppShapeInferenceResult_HandleShapeAndType::MergeFrom(const CppShapeInferenceResult_HandleShapeAndType& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.CppShapeInferenceResult.HandleShapeAndType)
  if (GOOGLE_PREDICT_TRUE(&from != this)) {
    UnsafeMergeFrom(from);
  } else {
    MergeFromFail(__LINE__);
  }
}

void CppShapeInferenceResult_HandleShapeAndType::UnsafeMergeFrom(const CppShapeInferenceResult_HandleShapeAndType& from) {
  GOOGLE_DCHECK(&from != this);
  if (from.has_shape()) {
    mutable_shape()->::tensorflow::TensorShapeProto::MergeFrom(from.shape());
  }
  if (from.dtype() != 0) {
    set_dtype(from.dtype());
  }
}

void CppShapeInferenceResult_HandleShapeAndType::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.CppShapeInferenceResult.HandleShapeAndType)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void CppShapeInferenceResult_HandleShapeAndType::CopyFrom(const CppShapeInferenceResult_HandleShapeAndType& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.CppShapeInferenceResult.HandleShapeAndType)
  if (&from == this) return;
  Clear();
  UnsafeMergeFrom(from);
}

bool CppShapeInferenceResult_HandleShapeAndType::IsInitialized() const {

  return true;
}

void CppShapeInferenceResult_HandleShapeAndType::Swap(CppShapeInferenceResult_HandleShapeAndType* other) {
  if (other == this) return;
  if (GetArenaNoVirtual() == other->GetArenaNoVirtual()) {
    InternalSwap(other);
  } else {
    CppShapeInferenceResult_HandleShapeAndType temp;
    temp.UnsafeMergeFrom(*this);
    CopyFrom(*other);
    other->CopyFrom(temp);
  }
}
void CppShapeInferenceResult_HandleShapeAndType::UnsafeArenaSwap(CppShapeInferenceResult_HandleShapeAndType* other) {
  if (other == this) return;
  GOOGLE_DCHECK(GetArenaNoVirtual() == other->GetArenaNoVirtual());
  InternalSwap(other);
}
void CppShapeInferenceResult_HandleShapeAndType::InternalSwap(CppShapeInferenceResult_HandleShapeAndType* other) {
  std::swap(shape_, other->shape_);
  std::swap(dtype_, other->dtype_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata CppShapeInferenceResult_HandleShapeAndType::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = CppShapeInferenceResult_HandleShapeAndType_descriptor_;
  metadata.reflection = CppShapeInferenceResult_HandleShapeAndType_reflection_;
  return metadata;
}


// -------------------------------------------------------------------

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int CppShapeInferenceResult_HandleData::kIsSetFieldNumber;
const int CppShapeInferenceResult_HandleData::kShapeAndTypeFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

CppShapeInferenceResult_HandleData::CppShapeInferenceResult_HandleData()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  if (this != internal_default_instance()) protobuf_InitDefaults_tensorflow_2fpython_2fframework_2fcpp_5fshape_5finference_2eproto();
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.CppShapeInferenceResult.HandleData)
}
CppShapeInferenceResult_HandleData::CppShapeInferenceResult_HandleData(::google::protobuf::Arena* arena)
  : ::google::protobuf::Message(),
  _internal_metadata_(arena),
  shape_and_type_(arena) {
#ifdef GOOGLE_PROTOBUF_NO_STATIC_INITIALIZER
  protobuf_InitDefaults_tensorflow_2fpython_2fframework_2fcpp_5fshape_5finference_2eproto();
#endif  // GOOGLE_PROTOBUF_NO_STATIC_INITIALIZER
  SharedCtor();
  RegisterArenaDtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.CppShapeInferenceResult.HandleData)
}

void CppShapeInferenceResult_HandleData::InitAsDefaultInstance() {
}

CppShapeInferenceResult_HandleData::CppShapeInferenceResult_HandleData(const CppShapeInferenceResult_HandleData& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  UnsafeMergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.CppShapeInferenceResult.HandleData)
}

void CppShapeInferenceResult_HandleData::SharedCtor() {
  is_set_ = false;
  _cached_size_ = 0;
}

CppShapeInferenceResult_HandleData::~CppShapeInferenceResult_HandleData() {
  // @@protoc_insertion_point(destructor:tensorflow.CppShapeInferenceResult.HandleData)
  SharedDtor();
}

void CppShapeInferenceResult_HandleData::SharedDtor() {
  ::google::protobuf::Arena* arena = GetArenaNoVirtual();
  if (arena != NULL) {
    return;
  }

}

void CppShapeInferenceResult_HandleData::ArenaDtor(void* object) {
  CppShapeInferenceResult_HandleData* _this = reinterpret_cast< CppShapeInferenceResult_HandleData* >(object);
  (void)_this;
}
void CppShapeInferenceResult_HandleData::RegisterArenaDtor(::google::protobuf::Arena* arena) {
}
void CppShapeInferenceResult_HandleData::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* CppShapeInferenceResult_HandleData::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return CppShapeInferenceResult_HandleData_descriptor_;
}

const CppShapeInferenceResult_HandleData& CppShapeInferenceResult_HandleData::default_instance() {
  protobuf_InitDefaults_tensorflow_2fpython_2fframework_2fcpp_5fshape_5finference_2eproto();
  return *internal_default_instance();
}

::google::protobuf::internal::ExplicitlyConstructed<CppShapeInferenceResult_HandleData> CppShapeInferenceResult_HandleData_default_instance_;

CppShapeInferenceResult_HandleData* CppShapeInferenceResult_HandleData::New(::google::protobuf::Arena* arena) const {
  return ::google::protobuf::Arena::CreateMessage<CppShapeInferenceResult_HandleData>(arena);
}

void CppShapeInferenceResult_HandleData::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.CppShapeInferenceResult.HandleData)
  is_set_ = false;
  shape_and_type_.Clear();
}

bool CppShapeInferenceResult_HandleData::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.CppShapeInferenceResult.HandleData)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional bool is_set = 1;
      case 1: {
        if (tag == 8) {

          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   bool, ::google::protobuf::internal::WireFormatLite::TYPE_BOOL>(
                 input, &is_set_)));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(18)) goto parse_shape_and_type;
        break;
      }

      // repeated .tensorflow.CppShapeInferenceResult.HandleShapeAndType shape_and_type = 2;
      case 2: {
        if (tag == 18) {
         parse_shape_and_type:
          DO_(input->IncrementRecursionDepth());
         parse_loop_shape_and_type:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtualNoRecursionDepth(
                input, add_shape_and_type()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(18)) goto parse_loop_shape_and_type;
        input->UnsafeDecrementRecursionDepth();
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.CppShapeInferenceResult.HandleData)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.CppShapeInferenceResult.HandleData)
  return false;
#undef DO_
}

void CppShapeInferenceResult_HandleData::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.CppShapeInferenceResult.HandleData)
  // optional bool is_set = 1;
  if (this->is_set() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteBool(1, this->is_set(), output);
  }

  // repeated .tensorflow.CppShapeInferenceResult.HandleShapeAndType shape_and_type = 2;
  for (unsigned int i = 0, n = this->shape_and_type_size(); i < n; i++) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      2, this->shape_and_type(i), output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.CppShapeInferenceResult.HandleData)
}

::google::protobuf::uint8* CppShapeInferenceResult_HandleData::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  (void)deterministic; // Unused
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.CppShapeInferenceResult.HandleData)
  // optional bool is_set = 1;
  if (this->is_set() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteBoolToArray(1, this->is_set(), target);
  }

  // repeated .tensorflow.CppShapeInferenceResult.HandleShapeAndType shape_and_type = 2;
  for (unsigned int i = 0, n = this->shape_and_type_size(); i < n; i++) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        2, this->shape_and_type(i), false, target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.CppShapeInferenceResult.HandleData)
  return target;
}

size_t CppShapeInferenceResult_HandleData::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.CppShapeInferenceResult.HandleData)
  size_t total_size = 0;

  // optional bool is_set = 1;
  if (this->is_set() != 0) {
    total_size += 1 + 1;
  }

  // repeated .tensorflow.CppShapeInferenceResult.HandleShapeAndType shape_and_type = 2;
  {
    unsigned int count = this->shape_and_type_size();
    total_size += 1UL * count;
    for (unsigned int i = 0; i < count; i++) {
      total_size +=
        ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
          this->shape_and_type(i));
    }
  }

  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = cached_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void CppShapeInferenceResult_HandleData::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.CppShapeInferenceResult.HandleData)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  const CppShapeInferenceResult_HandleData* source =
      ::google::protobuf::internal::DynamicCastToGenerated<const CppShapeInferenceResult_HandleData>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.CppShapeInferenceResult.HandleData)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.CppShapeInferenceResult.HandleData)
    UnsafeMergeFrom(*source);
  }
}

void CppShapeInferenceResult_HandleData::MergeFrom(const CppShapeInferenceResult_HandleData& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.CppShapeInferenceResult.HandleData)
  if (GOOGLE_PREDICT_TRUE(&from != this)) {
    UnsafeMergeFrom(from);
  } else {
    MergeFromFail(__LINE__);
  }
}

void CppShapeInferenceResult_HandleData::UnsafeMergeFrom(const CppShapeInferenceResult_HandleData& from) {
  GOOGLE_DCHECK(&from != this);
  shape_and_type_.MergeFrom(from.shape_and_type_);
  if (from.is_set() != 0) {
    set_is_set(from.is_set());
  }
}

void CppShapeInferenceResult_HandleData::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.CppShapeInferenceResult.HandleData)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void CppShapeInferenceResult_HandleData::CopyFrom(const CppShapeInferenceResult_HandleData& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.CppShapeInferenceResult.HandleData)
  if (&from == this) return;
  Clear();
  UnsafeMergeFrom(from);
}

bool CppShapeInferenceResult_HandleData::IsInitialized() const {

  return true;
}

void CppShapeInferenceResult_HandleData::Swap(CppShapeInferenceResult_HandleData* other) {
  if (other == this) return;
  if (GetArenaNoVirtual() == other->GetArenaNoVirtual()) {
    InternalSwap(other);
  } else {
    CppShapeInferenceResult_HandleData temp;
    temp.UnsafeMergeFrom(*this);
    CopyFrom(*other);
    other->CopyFrom(temp);
  }
}
void CppShapeInferenceResult_HandleData::UnsafeArenaSwap(CppShapeInferenceResult_HandleData* other) {
  if (other == this) return;
  GOOGLE_DCHECK(GetArenaNoVirtual() == other->GetArenaNoVirtual());
  InternalSwap(other);
}
void CppShapeInferenceResult_HandleData::InternalSwap(CppShapeInferenceResult_HandleData* other) {
  std::swap(is_set_, other->is_set_);
  shape_and_type_.UnsafeArenaSwap(&other->shape_and_type_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata CppShapeInferenceResult_HandleData::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = CppShapeInferenceResult_HandleData_descriptor_;
  metadata.reflection = CppShapeInferenceResult_HandleData_reflection_;
  return metadata;
}


// -------------------------------------------------------------------

void CppShapeInferenceResult::_slow_mutable_shape() {
  shape_ = ::google::protobuf::Arena::CreateMessage< ::tensorflow::TensorShapeProto >(
      GetArenaNoVirtual());
}
::tensorflow::TensorShapeProto* CppShapeInferenceResult::_slow_release_shape() {
  if (shape_ == NULL) {
    return NULL;
  } else {
    ::tensorflow::TensorShapeProto* temp = new ::tensorflow::TensorShapeProto(*shape_);
    shape_ = NULL;
    return temp;
  }
}
::tensorflow::TensorShapeProto* CppShapeInferenceResult::unsafe_arena_release_shape() {
  // @@protoc_insertion_point(field_unsafe_arena_release:tensorflow.CppShapeInferenceResult.shape)
  
  ::tensorflow::TensorShapeProto* temp = shape_;
  shape_ = NULL;
  return temp;
}
void CppShapeInferenceResult::_slow_set_allocated_shape(
    ::google::protobuf::Arena* message_arena, ::tensorflow::TensorShapeProto** shape) {
    if (message_arena != NULL && 
        ::google::protobuf::Arena::GetArena(*shape) == NULL) {
      message_arena->Own(*shape);
    } else if (message_arena !=
               ::google::protobuf::Arena::GetArena(*shape)) {
      ::tensorflow::TensorShapeProto* new_shape = 
            ::google::protobuf::Arena::CreateMessage< ::tensorflow::TensorShapeProto >(
            message_arena);
      new_shape->CopyFrom(**shape);
      *shape = new_shape;
    }
}
void CppShapeInferenceResult::unsafe_arena_set_allocated_shape(
    ::tensorflow::TensorShapeProto* shape) {
  if (GetArenaNoVirtual() == NULL) {
    delete shape_;
  }
  shape_ = shape;
  if (shape) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.CppShapeInferenceResult.shape)
}
void CppShapeInferenceResult::_slow_mutable_handle_data() {
  handle_data_ = ::google::protobuf::Arena::CreateMessage< ::tensorflow::CppShapeInferenceResult_HandleData >(
      GetArenaNoVirtual());
}
::tensorflow::CppShapeInferenceResult_HandleData* CppShapeInferenceResult::_slow_release_handle_data() {
  if (handle_data_ == NULL) {
    return NULL;
  } else {
    ::tensorflow::CppShapeInferenceResult_HandleData* temp = new ::tensorflow::CppShapeInferenceResult_HandleData(*handle_data_);
    handle_data_ = NULL;
    return temp;
  }
}
::tensorflow::CppShapeInferenceResult_HandleData* CppShapeInferenceResult::unsafe_arena_release_handle_data() {
  // @@protoc_insertion_point(field_unsafe_arena_release:tensorflow.CppShapeInferenceResult.handle_data)
  
  ::tensorflow::CppShapeInferenceResult_HandleData* temp = handle_data_;
  handle_data_ = NULL;
  return temp;
}
void CppShapeInferenceResult::_slow_set_allocated_handle_data(
    ::google::protobuf::Arena* message_arena, ::tensorflow::CppShapeInferenceResult_HandleData** handle_data) {
    if (message_arena != NULL && 
        ::google::protobuf::Arena::GetArena(*handle_data) == NULL) {
      message_arena->Own(*handle_data);
    } else if (message_arena !=
               ::google::protobuf::Arena::GetArena(*handle_data)) {
      ::tensorflow::CppShapeInferenceResult_HandleData* new_handle_data = 
            ::google::protobuf::Arena::CreateMessage< ::tensorflow::CppShapeInferenceResult_HandleData >(
            message_arena);
      new_handle_data->CopyFrom(**handle_data);
      *handle_data = new_handle_data;
    }
}
void CppShapeInferenceResult::unsafe_arena_set_allocated_handle_data(
    ::tensorflow::CppShapeInferenceResult_HandleData* handle_data) {
  if (GetArenaNoVirtual() == NULL) {
    delete handle_data_;
  }
  handle_data_ = handle_data;
  if (handle_data) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.CppShapeInferenceResult.handle_data)
}
#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int CppShapeInferenceResult::kShapeFieldNumber;
const int CppShapeInferenceResult::kHandleDataFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

CppShapeInferenceResult::CppShapeInferenceResult()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  if (this != internal_default_instance()) protobuf_InitDefaults_tensorflow_2fpython_2fframework_2fcpp_5fshape_5finference_2eproto();
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.CppShapeInferenceResult)
}
CppShapeInferenceResult::CppShapeInferenceResult(::google::protobuf::Arena* arena)
  : ::google::protobuf::Message(),
  _internal_metadata_(arena) {
#ifdef GOOGLE_PROTOBUF_NO_STATIC_INITIALIZER
  protobuf_InitDefaults_tensorflow_2fpython_2fframework_2fcpp_5fshape_5finference_2eproto();
#endif  // GOOGLE_PROTOBUF_NO_STATIC_INITIALIZER
  SharedCtor();
  RegisterArenaDtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.CppShapeInferenceResult)
}

void CppShapeInferenceResult::InitAsDefaultInstance() {
  shape_ = const_cast< ::tensorflow::TensorShapeProto*>(
      ::tensorflow::TensorShapeProto::internal_default_instance());
  handle_data_ = const_cast< ::tensorflow::CppShapeInferenceResult_HandleData*>(
      ::tensorflow::CppShapeInferenceResult_HandleData::internal_default_instance());
}

CppShapeInferenceResult::CppShapeInferenceResult(const CppShapeInferenceResult& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  UnsafeMergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.CppShapeInferenceResult)
}

void CppShapeInferenceResult::SharedCtor() {
  shape_ = NULL;
  handle_data_ = NULL;
  _cached_size_ = 0;
}

CppShapeInferenceResult::~CppShapeInferenceResult() {
  // @@protoc_insertion_point(destructor:tensorflow.CppShapeInferenceResult)
  SharedDtor();
}

void CppShapeInferenceResult::SharedDtor() {
  ::google::protobuf::Arena* arena = GetArenaNoVirtual();
  if (arena != NULL) {
    return;
  }

  if (this != &CppShapeInferenceResult_default_instance_.get()) {
    delete shape_;
    delete handle_data_;
  }
}

void CppShapeInferenceResult::ArenaDtor(void* object) {
  CppShapeInferenceResult* _this = reinterpret_cast< CppShapeInferenceResult* >(object);
  (void)_this;
}
void CppShapeInferenceResult::RegisterArenaDtor(::google::protobuf::Arena* arena) {
}
void CppShapeInferenceResult::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* CppShapeInferenceResult::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return CppShapeInferenceResult_descriptor_;
}

const CppShapeInferenceResult& CppShapeInferenceResult::default_instance() {
  protobuf_InitDefaults_tensorflow_2fpython_2fframework_2fcpp_5fshape_5finference_2eproto();
  return *internal_default_instance();
}

::google::protobuf::internal::ExplicitlyConstructed<CppShapeInferenceResult> CppShapeInferenceResult_default_instance_;

CppShapeInferenceResult* CppShapeInferenceResult::New(::google::protobuf::Arena* arena) const {
  return ::google::protobuf::Arena::CreateMessage<CppShapeInferenceResult>(arena);
}

void CppShapeInferenceResult::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.CppShapeInferenceResult)
  if (GetArenaNoVirtual() == NULL && shape_ != NULL) delete shape_;
  shape_ = NULL;
  if (GetArenaNoVirtual() == NULL && handle_data_ != NULL) delete handle_data_;
  handle_data_ = NULL;
}

bool CppShapeInferenceResult::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.CppShapeInferenceResult)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // optional .tensorflow.TensorShapeProto shape = 1;
      case 1: {
        if (tag == 10) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_shape()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(34)) goto parse_handle_data;
        break;
      }

      // optional .tensorflow.CppShapeInferenceResult.HandleData handle_data = 4;
      case 4: {
        if (tag == 34) {
         parse_handle_data:
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_handle_data()));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.CppShapeInferenceResult)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.CppShapeInferenceResult)
  return false;
#undef DO_
}

void CppShapeInferenceResult::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.CppShapeInferenceResult)
  // optional .tensorflow.TensorShapeProto shape = 1;
  if (this->has_shape()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, *this->shape_, output);
  }

  // optional .tensorflow.CppShapeInferenceResult.HandleData handle_data = 4;
  if (this->has_handle_data()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      4, *this->handle_data_, output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.CppShapeInferenceResult)
}

::google::protobuf::uint8* CppShapeInferenceResult::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  (void)deterministic; // Unused
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.CppShapeInferenceResult)
  // optional .tensorflow.TensorShapeProto shape = 1;
  if (this->has_shape()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        1, *this->shape_, false, target);
  }

  // optional .tensorflow.CppShapeInferenceResult.HandleData handle_data = 4;
  if (this->has_handle_data()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        4, *this->handle_data_, false, target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.CppShapeInferenceResult)
  return target;
}

size_t CppShapeInferenceResult::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.CppShapeInferenceResult)
  size_t total_size = 0;

  // optional .tensorflow.TensorShapeProto shape = 1;
  if (this->has_shape()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->shape_);
  }

  // optional .tensorflow.CppShapeInferenceResult.HandleData handle_data = 4;
  if (this->has_handle_data()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->handle_data_);
  }

  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = cached_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void CppShapeInferenceResult::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.CppShapeInferenceResult)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  const CppShapeInferenceResult* source =
      ::google::protobuf::internal::DynamicCastToGenerated<const CppShapeInferenceResult>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.CppShapeInferenceResult)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.CppShapeInferenceResult)
    UnsafeMergeFrom(*source);
  }
}

void CppShapeInferenceResult::MergeFrom(const CppShapeInferenceResult& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.CppShapeInferenceResult)
  if (GOOGLE_PREDICT_TRUE(&from != this)) {
    UnsafeMergeFrom(from);
  } else {
    MergeFromFail(__LINE__);
  }
}

void CppShapeInferenceResult::UnsafeMergeFrom(const CppShapeInferenceResult& from) {
  GOOGLE_DCHECK(&from != this);
  if (from.has_shape()) {
    mutable_shape()->::tensorflow::TensorShapeProto::MergeFrom(from.shape());
  }
  if (from.has_handle_data()) {
    mutable_handle_data()->::tensorflow::CppShapeInferenceResult_HandleData::MergeFrom(from.handle_data());
  }
}

void CppShapeInferenceResult::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.CppShapeInferenceResult)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void CppShapeInferenceResult::CopyFrom(const CppShapeInferenceResult& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.CppShapeInferenceResult)
  if (&from == this) return;
  Clear();
  UnsafeMergeFrom(from);
}

bool CppShapeInferenceResult::IsInitialized() const {

  return true;
}

void CppShapeInferenceResult::Swap(CppShapeInferenceResult* other) {
  if (other == this) return;
  if (GetArenaNoVirtual() == other->GetArenaNoVirtual()) {
    InternalSwap(other);
  } else {
    CppShapeInferenceResult temp;
    temp.UnsafeMergeFrom(*this);
    CopyFrom(*other);
    other->CopyFrom(temp);
  }
}
void CppShapeInferenceResult::UnsafeArenaSwap(CppShapeInferenceResult* other) {
  if (other == this) return;
  GOOGLE_DCHECK(GetArenaNoVirtual() == other->GetArenaNoVirtual());
  InternalSwap(other);
}
void CppShapeInferenceResult::InternalSwap(CppShapeInferenceResult* other) {
  std::swap(shape_, other->shape_);
  std::swap(handle_data_, other->handle_data_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata CppShapeInferenceResult::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = CppShapeInferenceResult_descriptor_;
  metadata.reflection = CppShapeInferenceResult_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// CppShapeInferenceResult_HandleShapeAndType

// optional .tensorflow.TensorShapeProto shape = 1;
bool CppShapeInferenceResult_HandleShapeAndType::has_shape() const {
  return this != internal_default_instance() && shape_ != NULL;
}
void CppShapeInferenceResult_HandleShapeAndType::clear_shape() {
  if (GetArenaNoVirtual() == NULL && shape_ != NULL) delete shape_;
  shape_ = NULL;
}
const ::tensorflow::TensorShapeProto& CppShapeInferenceResult_HandleShapeAndType::shape() const {
  // @@protoc_insertion_point(field_get:tensorflow.CppShapeInferenceResult.HandleShapeAndType.shape)
  return shape_ != NULL ? *shape_
                         : *::tensorflow::TensorShapeProto::internal_default_instance();
}
::tensorflow::TensorShapeProto* CppShapeInferenceResult_HandleShapeAndType::mutable_shape() {
  
  if (shape_ == NULL) {
    _slow_mutable_shape();
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.CppShapeInferenceResult.HandleShapeAndType.shape)
  return shape_;
}
::tensorflow::TensorShapeProto* CppShapeInferenceResult_HandleShapeAndType::release_shape() {
  // @@protoc_insertion_point(field_release:tensorflow.CppShapeInferenceResult.HandleShapeAndType.shape)
  
  if (GetArenaNoVirtual() != NULL) {
    return _slow_release_shape();
  } else {
    ::tensorflow::TensorShapeProto* temp = shape_;
    shape_ = NULL;
    return temp;
  }
}
 void CppShapeInferenceResult_HandleShapeAndType::set_allocated_shape(::tensorflow::TensorShapeProto* shape) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete shape_;
  }
  if (shape != NULL) {
    _slow_set_allocated_shape(message_arena, &shape);
  }
  shape_ = shape;
  if (shape) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.CppShapeInferenceResult.HandleShapeAndType.shape)
}

// optional .tensorflow.DataType dtype = 2;
void CppShapeInferenceResult_HandleShapeAndType::clear_dtype() {
  dtype_ = 0;
}
::tensorflow::DataType CppShapeInferenceResult_HandleShapeAndType::dtype() const {
  // @@protoc_insertion_point(field_get:tensorflow.CppShapeInferenceResult.HandleShapeAndType.dtype)
  return static_cast< ::tensorflow::DataType >(dtype_);
}
void CppShapeInferenceResult_HandleShapeAndType::set_dtype(::tensorflow::DataType value) {
  
  dtype_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.CppShapeInferenceResult.HandleShapeAndType.dtype)
}

inline const CppShapeInferenceResult_HandleShapeAndType* CppShapeInferenceResult_HandleShapeAndType::internal_default_instance() {
  return &CppShapeInferenceResult_HandleShapeAndType_default_instance_.get();
}
// -------------------------------------------------------------------

// CppShapeInferenceResult_HandleData

// optional bool is_set = 1;
void CppShapeInferenceResult_HandleData::clear_is_set() {
  is_set_ = false;
}
bool CppShapeInferenceResult_HandleData::is_set() const {
  // @@protoc_insertion_point(field_get:tensorflow.CppShapeInferenceResult.HandleData.is_set)
  return is_set_;
}
void CppShapeInferenceResult_HandleData::set_is_set(bool value) {
  
  is_set_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.CppShapeInferenceResult.HandleData.is_set)
}

// repeated .tensorflow.CppShapeInferenceResult.HandleShapeAndType shape_and_type = 2;
int CppShapeInferenceResult_HandleData::shape_and_type_size() const {
  return shape_and_type_.size();
}
void CppShapeInferenceResult_HandleData::clear_shape_and_type() {
  shape_and_type_.Clear();
}
const ::tensorflow::CppShapeInferenceResult_HandleShapeAndType& CppShapeInferenceResult_HandleData::shape_and_type(int index) const {
  // @@protoc_insertion_point(field_get:tensorflow.CppShapeInferenceResult.HandleData.shape_and_type)
  return shape_and_type_.Get(index);
}
::tensorflow::CppShapeInferenceResult_HandleShapeAndType* CppShapeInferenceResult_HandleData::mutable_shape_and_type(int index) {
  // @@protoc_insertion_point(field_mutable:tensorflow.CppShapeInferenceResult.HandleData.shape_and_type)
  return shape_and_type_.Mutable(index);
}
::tensorflow::CppShapeInferenceResult_HandleShapeAndType* CppShapeInferenceResult_HandleData::add_shape_and_type() {
  // @@protoc_insertion_point(field_add:tensorflow.CppShapeInferenceResult.HandleData.shape_and_type)
  return shape_and_type_.Add();
}
::google::protobuf::RepeatedPtrField< ::tensorflow::CppShapeInferenceResult_HandleShapeAndType >*
CppShapeInferenceResult_HandleData::mutable_shape_and_type() {
  // @@protoc_insertion_point(field_mutable_list:tensorflow.CppShapeInferenceResult.HandleData.shape_and_type)
  return &shape_and_type_;
}
const ::google::protobuf::RepeatedPtrField< ::tensorflow::CppShapeInferenceResult_HandleShapeAndType >&
CppShapeInferenceResult_HandleData::shape_and_type() const {
  // @@protoc_insertion_point(field_list:tensorflow.CppShapeInferenceResult.HandleData.shape_and_type)
  return shape_and_type_;
}

inline const CppShapeInferenceResult_HandleData* CppShapeInferenceResult_HandleData::internal_default_instance() {
  return &CppShapeInferenceResult_HandleData_default_instance_.get();
}
// -------------------------------------------------------------------

// CppShapeInferenceResult

// optional .tensorflow.TensorShapeProto shape = 1;
bool CppShapeInferenceResult::has_shape() const {
  return this != internal_default_instance() && shape_ != NULL;
}
void CppShapeInferenceResult::clear_shape() {
  if (GetArenaNoVirtual() == NULL && shape_ != NULL) delete shape_;
  shape_ = NULL;
}
const ::tensorflow::TensorShapeProto& CppShapeInferenceResult::shape() const {
  // @@protoc_insertion_point(field_get:tensorflow.CppShapeInferenceResult.shape)
  return shape_ != NULL ? *shape_
                         : *::tensorflow::TensorShapeProto::internal_default_instance();
}
::tensorflow::TensorShapeProto* CppShapeInferenceResult::mutable_shape() {
  
  if (shape_ == NULL) {
    _slow_mutable_shape();
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.CppShapeInferenceResult.shape)
  return shape_;
}
::tensorflow::TensorShapeProto* CppShapeInferenceResult::release_shape() {
  // @@protoc_insertion_point(field_release:tensorflow.CppShapeInferenceResult.shape)
  
  if (GetArenaNoVirtual() != NULL) {
    return _slow_release_shape();
  } else {
    ::tensorflow::TensorShapeProto* temp = shape_;
    shape_ = NULL;
    return temp;
  }
}
 void CppShapeInferenceResult::set_allocated_shape(::tensorflow::TensorShapeProto* shape) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete shape_;
  }
  if (shape != NULL) {
    _slow_set_allocated_shape(message_arena, &shape);
  }
  shape_ = shape;
  if (shape) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.CppShapeInferenceResult.shape)
}

// optional .tensorflow.CppShapeInferenceResult.HandleData handle_data = 4;
bool CppShapeInferenceResult::has_handle_data() const {
  return this != internal_default_instance() && handle_data_ != NULL;
}
void CppShapeInferenceResult::clear_handle_data() {
  if (GetArenaNoVirtual() == NULL && handle_data_ != NULL) delete handle_data_;
  handle_data_ = NULL;
}
const ::tensorflow::CppShapeInferenceResult_HandleData& CppShapeInferenceResult::handle_data() const {
  // @@protoc_insertion_point(field_get:tensorflow.CppShapeInferenceResult.handle_data)
  return handle_data_ != NULL ? *handle_data_
                         : *::tensorflow::CppShapeInferenceResult_HandleData::internal_default_instance();
}
::tensorflow::CppShapeInferenceResult_HandleData* CppShapeInferenceResult::mutable_handle_data() {
  
  if (handle_data_ == NULL) {
    _slow_mutable_handle_data();
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.CppShapeInferenceResult.handle_data)
  return handle_data_;
}
::tensorflow::CppShapeInferenceResult_HandleData* CppShapeInferenceResult::release_handle_data() {
  // @@protoc_insertion_point(field_release:tensorflow.CppShapeInferenceResult.handle_data)
  
  if (GetArenaNoVirtual() != NULL) {
    return _slow_release_handle_data();
  } else {
    ::tensorflow::CppShapeInferenceResult_HandleData* temp = handle_data_;
    handle_data_ = NULL;
    return temp;
  }
}
 void CppShapeInferenceResult::set_allocated_handle_data(::tensorflow::CppShapeInferenceResult_HandleData* handle_data) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete handle_data_;
  }
  if (handle_data != NULL) {
    _slow_set_allocated_handle_data(message_arena, &handle_data);
  }
  handle_data_ = handle_data;
  if (handle_data) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.CppShapeInferenceResult.handle_data)
}

inline const CppShapeInferenceResult* CppShapeInferenceResult::internal_default_instance() {
  return &CppShapeInferenceResult_default_instance_.get();
}
#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int CppShapeInferenceInputsNeeded::kInputTensorsNeededFieldNumber;
const int CppShapeInferenceInputsNeeded::kInputTensorsAsShapesNeededFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

CppShapeInferenceInputsNeeded::CppShapeInferenceInputsNeeded()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  if (this != internal_default_instance()) protobuf_InitDefaults_tensorflow_2fpython_2fframework_2fcpp_5fshape_5finference_2eproto();
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.CppShapeInferenceInputsNeeded)
}
CppShapeInferenceInputsNeeded::CppShapeInferenceInputsNeeded(::google::protobuf::Arena* arena)
  : ::google::protobuf::Message(),
  _internal_metadata_(arena),
  input_tensors_needed_(arena),
  input_tensors_as_shapes_needed_(arena) {
#ifdef GOOGLE_PROTOBUF_NO_STATIC_INITIALIZER
  protobuf_InitDefaults_tensorflow_2fpython_2fframework_2fcpp_5fshape_5finference_2eproto();
#endif  // GOOGLE_PROTOBUF_NO_STATIC_INITIALIZER
  SharedCtor();
  RegisterArenaDtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.CppShapeInferenceInputsNeeded)
}

void CppShapeInferenceInputsNeeded::InitAsDefaultInstance() {
}

CppShapeInferenceInputsNeeded::CppShapeInferenceInputsNeeded(const CppShapeInferenceInputsNeeded& from)
  : ::google::protobuf::Message(),
    _internal_metadata_(NULL) {
  SharedCtor();
  UnsafeMergeFrom(from);
  // @@protoc_insertion_point(copy_constructor:tensorflow.CppShapeInferenceInputsNeeded)
}

void CppShapeInferenceInputsNeeded::SharedCtor() {
  _cached_size_ = 0;
}

CppShapeInferenceInputsNeeded::~CppShapeInferenceInputsNeeded() {
  // @@protoc_insertion_point(destructor:tensorflow.CppShapeInferenceInputsNeeded)
  SharedDtor();
}

void CppShapeInferenceInputsNeeded::SharedDtor() {
  ::google::protobuf::Arena* arena = GetArenaNoVirtual();
  if (arena != NULL) {
    return;
  }

}

void CppShapeInferenceInputsNeeded::ArenaDtor(void* object) {
  CppShapeInferenceInputsNeeded* _this = reinterpret_cast< CppShapeInferenceInputsNeeded* >(object);
  (void)_this;
}
void CppShapeInferenceInputsNeeded::RegisterArenaDtor(::google::protobuf::Arena* arena) {
}
void CppShapeInferenceInputsNeeded::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* CppShapeInferenceInputsNeeded::descriptor() {
  protobuf_AssignDescriptorsOnce();
  return CppShapeInferenceInputsNeeded_descriptor_;
}

const CppShapeInferenceInputsNeeded& CppShapeInferenceInputsNeeded::default_instance() {
  protobuf_InitDefaults_tensorflow_2fpython_2fframework_2fcpp_5fshape_5finference_2eproto();
  return *internal_default_instance();
}

::google::protobuf::internal::ExplicitlyConstructed<CppShapeInferenceInputsNeeded> CppShapeInferenceInputsNeeded_default_instance_;

CppShapeInferenceInputsNeeded* CppShapeInferenceInputsNeeded::New(::google::protobuf::Arena* arena) const {
  return ::google::protobuf::Arena::CreateMessage<CppShapeInferenceInputsNeeded>(arena);
}

void CppShapeInferenceInputsNeeded::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.CppShapeInferenceInputsNeeded)
  input_tensors_needed_.Clear();
  input_tensors_as_shapes_needed_.Clear();
}

bool CppShapeInferenceInputsNeeded::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.CppShapeInferenceInputsNeeded)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoff(127);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // repeated int32 input_tensors_needed = 1;
      case 1: {
        if (tag == 10) {
          DO_((::google::protobuf::internal::WireFormatLite::ReadPackedPrimitive<
                   ::google::protobuf::int32, ::google::protobuf::internal::WireFormatLite::TYPE_INT32>(
                 input, this->mutable_input_tensors_needed())));
        } else if (tag == 8) {
          DO_((::google::protobuf::internal::WireFormatLite::ReadRepeatedPrimitiveNoInline<
                   ::google::protobuf::int32, ::google::protobuf::internal::WireFormatLite::TYPE_INT32>(
                 1, 10, input, this->mutable_input_tensors_needed())));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectTag(18)) goto parse_input_tensors_as_shapes_needed;
        break;
      }

      // repeated int32 input_tensors_as_shapes_needed = 2;
      case 2: {
        if (tag == 18) {
         parse_input_tensors_as_shapes_needed:
          DO_((::google::protobuf::internal::WireFormatLite::ReadPackedPrimitive<
                   ::google::protobuf::int32, ::google::protobuf::internal::WireFormatLite::TYPE_INT32>(
                 input, this->mutable_input_tensors_as_shapes_needed())));
        } else if (tag == 16) {
          DO_((::google::protobuf::internal::WireFormatLite::ReadRepeatedPrimitiveNoInline<
                   ::google::protobuf::int32, ::google::protobuf::internal::WireFormatLite::TYPE_INT32>(
                 1, 18, input, this->mutable_input_tensors_as_shapes_needed())));
        } else {
          goto handle_unusual;
        }
        if (input->ExpectAtEnd()) goto success;
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.CppShapeInferenceInputsNeeded)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.CppShapeInferenceInputsNeeded)
  return false;
#undef DO_
}

void CppShapeInferenceInputsNeeded::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.CppShapeInferenceInputsNeeded)
  // repeated int32 input_tensors_needed = 1;
  if (this->input_tensors_needed_size() > 0) {
    ::google::protobuf::internal::WireFormatLite::WriteTag(1, ::google::protobuf::internal::WireFormatLite::WIRETYPE_LENGTH_DELIMITED, output);
    output->WriteVarint32(_input_tensors_needed_cached_byte_size_);
  }
  for (int i = 0; i < this->input_tensors_needed_size(); i++) {
    ::google::protobuf::internal::WireFormatLite::WriteInt32NoTag(
      this->input_tensors_needed(i), output);
  }

  // repeated int32 input_tensors_as_shapes_needed = 2;
  if (this->input_tensors_as_shapes_needed_size() > 0) {
    ::google::protobuf::internal::WireFormatLite::WriteTag(2, ::google::protobuf::internal::WireFormatLite::WIRETYPE_LENGTH_DELIMITED, output);
    output->WriteVarint32(_input_tensors_as_shapes_needed_cached_byte_size_);
  }
  for (int i = 0; i < this->input_tensors_as_shapes_needed_size(); i++) {
    ::google::protobuf::internal::WireFormatLite::WriteInt32NoTag(
      this->input_tensors_as_shapes_needed(i), output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.CppShapeInferenceInputsNeeded)
}

::google::protobuf::uint8* CppShapeInferenceInputsNeeded::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  (void)deterministic; // Unused
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.CppShapeInferenceInputsNeeded)
  // repeated int32 input_tensors_needed = 1;
  if (this->input_tensors_needed_size() > 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteTagToArray(
      1,
      ::google::protobuf::internal::WireFormatLite::WIRETYPE_LENGTH_DELIMITED,
      target);
    target = ::google::protobuf::io::CodedOutputStream::WriteVarint32ToArray(
      _input_tensors_needed_cached_byte_size_, target);
  }
  for (int i = 0; i < this->input_tensors_needed_size(); i++) {
    target = ::google::protobuf::internal::WireFormatLite::
      WriteInt32NoTagToArray(this->input_tensors_needed(i), target);
  }

  // repeated int32 input_tensors_as_shapes_needed = 2;
  if (this->input_tensors_as_shapes_needed_size() > 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteTagToArray(
      2,
      ::google::protobuf::internal::WireFormatLite::WIRETYPE_LENGTH_DELIMITED,
      target);
    target = ::google::protobuf::io::CodedOutputStream::WriteVarint32ToArray(
      _input_tensors_as_shapes_needed_cached_byte_size_, target);
  }
  for (int i = 0; i < this->input_tensors_as_shapes_needed_size(); i++) {
    target = ::google::protobuf::internal::WireFormatLite::
      WriteInt32NoTagToArray(this->input_tensors_as_shapes_needed(i), target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.CppShapeInferenceInputsNeeded)
  return target;
}

size_t CppShapeInferenceInputsNeeded::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.CppShapeInferenceInputsNeeded)
  size_t total_size = 0;

  // repeated int32 input_tensors_needed = 1;
  {
    size_t data_size = 0;
    unsigned int count = this->input_tensors_needed_size();
    for (unsigned int i = 0; i < count; i++) {
      data_size += ::google::protobuf::internal::WireFormatLite::
        Int32Size(this->input_tensors_needed(i));
    }
    if (data_size > 0) {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::Int32Size(data_size);
    }
    int cached_size = ::google::protobuf::internal::ToCachedSize(data_size);
    GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
    _input_tensors_needed_cached_byte_size_ = cached_size;
    GOOGLE_SAFE_CONCURRENT_WRITES_END();
    total_size += data_size;
  }

  // repeated int32 input_tensors_as_shapes_needed = 2;
  {
    size_t data_size = 0;
    unsigned int count = this->input_tensors_as_shapes_needed_size();
    for (unsigned int i = 0; i < count; i++) {
      data_size += ::google::protobuf::internal::WireFormatLite::
        Int32Size(this->input_tensors_as_shapes_needed(i));
    }
    if (data_size > 0) {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::Int32Size(data_size);
    }
    int cached_size = ::google::protobuf::internal::ToCachedSize(data_size);
    GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
    _input_tensors_as_shapes_needed_cached_byte_size_ = cached_size;
    GOOGLE_SAFE_CONCURRENT_WRITES_END();
    total_size += data_size;
  }

  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = cached_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void CppShapeInferenceInputsNeeded::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.CppShapeInferenceInputsNeeded)
  if (GOOGLE_PREDICT_FALSE(&from == this)) MergeFromFail(__LINE__);
  const CppShapeInferenceInputsNeeded* source =
      ::google::protobuf::internal::DynamicCastToGenerated<const CppShapeInferenceInputsNeeded>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.CppShapeInferenceInputsNeeded)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.CppShapeInferenceInputsNeeded)
    UnsafeMergeFrom(*source);
  }
}

void CppShapeInferenceInputsNeeded::MergeFrom(const CppShapeInferenceInputsNeeded& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.CppShapeInferenceInputsNeeded)
  if (GOOGLE_PREDICT_TRUE(&from != this)) {
    UnsafeMergeFrom(from);
  } else {
    MergeFromFail(__LINE__);
  }
}

void CppShapeInferenceInputsNeeded::UnsafeMergeFrom(const CppShapeInferenceInputsNeeded& from) {
  GOOGLE_DCHECK(&from != this);
  input_tensors_needed_.UnsafeMergeFrom(from.input_tensors_needed_);
  input_tensors_as_shapes_needed_.UnsafeMergeFrom(from.input_tensors_as_shapes_needed_);
}

void CppShapeInferenceInputsNeeded::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.CppShapeInferenceInputsNeeded)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void CppShapeInferenceInputsNeeded::CopyFrom(const CppShapeInferenceInputsNeeded& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.CppShapeInferenceInputsNeeded)
  if (&from == this) return;
  Clear();
  UnsafeMergeFrom(from);
}

bool CppShapeInferenceInputsNeeded::IsInitialized() const {

  return true;
}

void CppShapeInferenceInputsNeeded::Swap(CppShapeInferenceInputsNeeded* other) {
  if (other == this) return;
  if (GetArenaNoVirtual() == other->GetArenaNoVirtual()) {
    InternalSwap(other);
  } else {
    CppShapeInferenceInputsNeeded temp;
    temp.UnsafeMergeFrom(*this);
    CopyFrom(*other);
    other->CopyFrom(temp);
  }
}
void CppShapeInferenceInputsNeeded::UnsafeArenaSwap(CppShapeInferenceInputsNeeded* other) {
  if (other == this) return;
  GOOGLE_DCHECK(GetArenaNoVirtual() == other->GetArenaNoVirtual());
  InternalSwap(other);
}
void CppShapeInferenceInputsNeeded::InternalSwap(CppShapeInferenceInputsNeeded* other) {
  input_tensors_needed_.UnsafeArenaSwap(&other->input_tensors_needed_);
  input_tensors_as_shapes_needed_.UnsafeArenaSwap(&other->input_tensors_as_shapes_needed_);
  _internal_metadata_.Swap(&other->_internal_metadata_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata CppShapeInferenceInputsNeeded::GetMetadata() const {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::Metadata metadata;
  metadata.descriptor = CppShapeInferenceInputsNeeded_descriptor_;
  metadata.reflection = CppShapeInferenceInputsNeeded_reflection_;
  return metadata;
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// CppShapeInferenceInputsNeeded

// repeated int32 input_tensors_needed = 1;
int CppShapeInferenceInputsNeeded::input_tensors_needed_size() const {
  return input_tensors_needed_.size();
}
void CppShapeInferenceInputsNeeded::clear_input_tensors_needed() {
  input_tensors_needed_.Clear();
}
::google::protobuf::int32 CppShapeInferenceInputsNeeded::input_tensors_needed(int index) const {
  // @@protoc_insertion_point(field_get:tensorflow.CppShapeInferenceInputsNeeded.input_tensors_needed)
  return input_tensors_needed_.Get(index);
}
void CppShapeInferenceInputsNeeded::set_input_tensors_needed(int index, ::google::protobuf::int32 value) {
  input_tensors_needed_.Set(index, value);
  // @@protoc_insertion_point(field_set:tensorflow.CppShapeInferenceInputsNeeded.input_tensors_needed)
}
void CppShapeInferenceInputsNeeded::add_input_tensors_needed(::google::protobuf::int32 value) {
  input_tensors_needed_.Add(value);
  // @@protoc_insertion_point(field_add:tensorflow.CppShapeInferenceInputsNeeded.input_tensors_needed)
}
const ::google::protobuf::RepeatedField< ::google::protobuf::int32 >&
CppShapeInferenceInputsNeeded::input_tensors_needed() const {
  // @@protoc_insertion_point(field_list:tensorflow.CppShapeInferenceInputsNeeded.input_tensors_needed)
  return input_tensors_needed_;
}
::google::protobuf::RepeatedField< ::google::protobuf::int32 >*
CppShapeInferenceInputsNeeded::mutable_input_tensors_needed() {
  // @@protoc_insertion_point(field_mutable_list:tensorflow.CppShapeInferenceInputsNeeded.input_tensors_needed)
  return &input_tensors_needed_;
}

// repeated int32 input_tensors_as_shapes_needed = 2;
int CppShapeInferenceInputsNeeded::input_tensors_as_shapes_needed_size() const {
  return input_tensors_as_shapes_needed_.size();
}
void CppShapeInferenceInputsNeeded::clear_input_tensors_as_shapes_needed() {
  input_tensors_as_shapes_needed_.Clear();
}
::google::protobuf::int32 CppShapeInferenceInputsNeeded::input_tensors_as_shapes_needed(int index) const {
  // @@protoc_insertion_point(field_get:tensorflow.CppShapeInferenceInputsNeeded.input_tensors_as_shapes_needed)
  return input_tensors_as_shapes_needed_.Get(index);
}
void CppShapeInferenceInputsNeeded::set_input_tensors_as_shapes_needed(int index, ::google::protobuf::int32 value) {
  input_tensors_as_shapes_needed_.Set(index, value);
  // @@protoc_insertion_point(field_set:tensorflow.CppShapeInferenceInputsNeeded.input_tensors_as_shapes_needed)
}
void CppShapeInferenceInputsNeeded::add_input_tensors_as_shapes_needed(::google::protobuf::int32 value) {
  input_tensors_as_shapes_needed_.Add(value);
  // @@protoc_insertion_point(field_add:tensorflow.CppShapeInferenceInputsNeeded.input_tensors_as_shapes_needed)
}
const ::google::protobuf::RepeatedField< ::google::protobuf::int32 >&
CppShapeInferenceInputsNeeded::input_tensors_as_shapes_needed() const {
  // @@protoc_insertion_point(field_list:tensorflow.CppShapeInferenceInputsNeeded.input_tensors_as_shapes_needed)
  return input_tensors_as_shapes_needed_;
}
::google::protobuf::RepeatedField< ::google::protobuf::int32 >*
CppShapeInferenceInputsNeeded::mutable_input_tensors_as_shapes_needed() {
  // @@protoc_insertion_point(field_mutable_list:tensorflow.CppShapeInferenceInputsNeeded.input_tensors_as_shapes_needed)
  return &input_tensors_as_shapes_needed_;
}

inline const CppShapeInferenceInputsNeeded* CppShapeInferenceInputsNeeded::internal_default_instance() {
  return &CppShapeInferenceInputsNeeded_default_instance_.get();
}
#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// @@protoc_insertion_point(namespace_scope)

}  // namespace tensorflow

// @@protoc_insertion_point(global_scope)
